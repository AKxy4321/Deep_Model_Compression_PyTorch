MODEL INITIALIZED AND WEIGHTS LOADED
EVALUATING PRE-TRAINED MODEL
Validation Accuracy: 94.00%
Validation Loss: 0.0018
Current FLOPS: 85091549184, Current params : 33646666
Validation accuracy  94.0
MAX VALIDATION ACCURACY = 94.0
STARTED PRUNING PROCESS
ITERATION 1 
OPTIMISING MODEL
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
/content/drive/MyDrive/Deep_Model_Compression_PyTorch/pruning_utils.py:316: RuntimeWarning: overflow encountered in exp
  regularizer_value = np.exp(regularizer_value)
Epoch 1/10 - Regularizer Value: inf
Optimizing 1/10: 100% 391/391 [00:25<00:00, 15.15it/s, acc=28.3, loss=inf]
val loss:inf, val acc:37.62
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 2/10 - Regularizer Value: inf
Optimizing 2/10: 100% 391/391 [00:25<00:00, 15.08it/s, acc=52.3, loss=inf]
val loss:inf, val acc:59.57
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 3/10 - Regularizer Value: inf
Optimizing 3/10: 100% 391/391 [00:26<00:00, 14.54it/s, acc=67.1, loss=inf]
val loss:inf, val acc:63.95
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 4/10 - Regularizer Value: inf
Optimizing 4/10: 100% 391/391 [00:26<00:00, 14.61it/s, acc=75.6, loss=inf]
val loss:inf, val acc:76.67
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 5/10 - Regularizer Value: inf
Optimizing 5/10: 100% 391/391 [00:26<00:00, 14.53it/s, acc=81, loss=inf]
val loss:inf, val acc:77.86
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 6/10 - Regularizer Value: inf
Optimizing 6/10: 100% 391/391 [00:26<00:00, 14.69it/s, acc=84.1, loss=inf]
val loss:inf, val acc:78.91
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 7/10 - Regularizer Value: inf
Optimizing 7/10: 100% 391/391 [00:26<00:00, 14.60it/s, acc=86.7, loss=inf]
val loss:inf, val acc:79.03
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 8/10 - Regularizer Value: inf
Optimizing 8/10: 100% 391/391 [00:26<00:00, 14.62it/s, acc=88.7, loss=inf]
val loss:inf, val acc:78.88
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 9/10 - Regularizer Value: inf
Optimizing 9/10: 100% 391/391 [00:26<00:00, 14.64it/s, acc=90, loss=inf]
val loss:inf, val acc:83.8
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
Epoch 10/10 - Regularizer Value: inf
Optimizing 10/10: 100% 391/391 [00:26<00:00, 14.64it/s, acc=91.4, loss=inf]
val loss:inf, val acc:84.25
FINAL REGULARIZER VALUE  inf
After optmization step :
EVALUATING PRE-TRAINED MODEL
Validation Accuracy: 84.25%
Validation Loss: 0.0044
PRUNING STARTED
NUM FILTERS BEFORE PRUNING: [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]
NUM FILTERS AFTER PRUNING: [62, 62, 126, 126, 254, 254, 254, 510, 510, 510, 510, 510, 510]
After filter deletion step :
EVALUATING PRE-TRAINED MODEL
Validation Accuracy: 82.13%
Validation Loss: 0.0047
TRAINING MODEL
Epoch 1/10: 100% 391/391 [00:26<00:00, 14.52it/s, acc=91.9, loss=0.00206]
Epoch 2/10: 100% 391/391 [00:27<00:00, 14.34it/s, acc=93.3, loss=0.00174]
Epoch 3/10: 100% 391/391 [00:26<00:00, 14.69it/s, acc=94, loss=0.00153]
Epoch 4/10: 100% 391/391 [00:26<00:00, 14.66it/s, acc=94.6, loss=0.00139]
Epoch 5/10: 100% 391/391 [00:26<00:00, 14.63it/s, acc=95.2, loss=0.00124]
Epoch 6/10: 100% 391/391 [00:26<00:00, 14.65it/s, acc=95.4, loss=0.00117]
Epoch 7/10: 100% 391/391 [00:26<00:00, 14.64it/s, acc=96.2, loss=0.00102]
Epoch 8/10: 100% 391/391 [00:26<00:00, 14.68it/s, acc=96.4, loss=0.000932]
Epoch 9/10: 100% 391/391 [00:26<00:00, 14.73it/s, acc=96.9, loss=0.000836]
Epoch 10/10: 100% 391/391 [00:26<00:00, 14.51it/s, acc=96.9, loss=0.000805]
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
val loss:0.004568039542436599, val acc:86.75
Best model weights loaded before returning! best val_acc:86.75
After retraining step immediately after filter deletion :
EVALUATING PRE-TRAINED MODEL
Validation Accuracy: 86.75%
Validation Loss: 0.0046
33497078 83278394880
Current FLOPS: 83278394880, Current params : 33497078
Validation accuracy  86.75
VALIDATION ACCURACY AFTER 1 ITERATIONS = 86.75
VGG(
  (features): Sequential(
    (0): Conv2d(3, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(62, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(126, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(126, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(126, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(126, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(254, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(254, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Sequential(
    (0): Linear(in_features=510, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
TRAINING MODEL
Epoch 1/30: 100% 391/391 [00:26<00:00, 14.56it/s, acc=97.1, loss=0.000778]
Epoch 2/30: 100% 391/391 [00:26<00:00, 14.67it/s, acc=97.2, loss=0.000743]
Epoch 3/30: 100% 391/391 [00:26<00:00, 14.69it/s, acc=97.6, loss=0.00066]
Epoch 4/30: 100% 391/391 [00:26<00:00, 14.70it/s, acc=97.7, loss=0.000601]
Epoch 5/30: 100% 391/391 [00:26<00:00, 14.64it/s, acc=97.6, loss=0.000651]
Epoch 6/30: 100% 391/391 [00:26<00:00, 14.50it/s, acc=98.1, loss=0.00054]
Epoch 7/30: 100% 391/391 [00:26<00:00, 14.67it/s, acc=98.1, loss=0.00053]
Epoch 8/30: 100% 391/391 [00:26<00:00, 14.77it/s, acc=97.9, loss=0.00056]
Epoch 9/30: 100% 391/391 [00:26<00:00, 14.76it/s, acc=98.1, loss=0.000516]
Epoch 10/30: 100% 391/391 [00:26<00:00, 14.78it/s, acc=98.3, loss=0.000447]
Epoch 11/30: 100% 391/391 [00:26<00:00, 14.81it/s, acc=98.3, loss=0.000453]
Epoch 12/30: 100% 391/391 [00:26<00:00, 14.70it/s, acc=98.5, loss=0.000413]
Epoch 13/30: 100% 391/391 [00:26<00:00, 14.74it/s, acc=98.5, loss=0.000401]
Epoch 14/30: 100% 391/391 [00:26<00:00, 14.54it/s, acc=98.6, loss=0.000385]
Epoch 15/30: 100% 391/391 [00:26<00:00, 14.65it/s, acc=98.6, loss=0.000397]
Epoch 16/30: 100% 391/391 [00:26<00:00, 14.71it/s, acc=98.7, loss=0.000352]
Epoch 17/30: 100% 391/391 [00:26<00:00, 14.73it/s, acc=98.8, loss=0.000349]
Epoch 18/30: 100% 391/391 [00:26<00:00, 14.73it/s, acc=98.5, loss=0.000413]
Epoch 19/30: 100% 391/391 [00:26<00:00, 14.70it/s, acc=98.8, loss=0.000337]
Epoch 20/30: 100% 391/391 [00:26<00:00, 14.74it/s, acc=98.9, loss=0.000297]
Epoch 21/30: 100% 391/391 [00:26<00:00, 14.65it/s, acc=98.8, loss=0.000344]
Epoch 22/30: 100% 391/391 [00:26<00:00, 14.66it/s, acc=98.8, loss=0.000331]
Epoch 23/30: 100% 391/391 [00:26<00:00, 14.74it/s, acc=98.9, loss=0.00032]
Epoch 24/30: 100% 391/391 [00:26<00:00, 14.77it/s, acc=98.9, loss=0.000315]
Epoch 25/30: 100% 391/391 [00:26<00:00, 14.74it/s, acc=98.9, loss=0.000298]
Epoch 26/30: 100% 391/391 [00:26<00:00, 14.77it/s, acc=99, loss=0.00028]
Epoch 27/30: 100% 391/391 [00:26<00:00, 14.75it/s, acc=99.1, loss=0.000257]
Epoch 28/30: 100% 391/391 [00:26<00:00, 14.75it/s, acc=99, loss=0.000286]
Epoch 29/30: 100% 391/391 [00:26<00:00, 14.63it/s, acc=99.2, loss=0.000227]
Epoch 30/30: 100% 391/391 [00:26<00:00, 14.76it/s, acc=99.1, loss=0.00026]
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
val loss:0.005851730477809906, val acc:86.03
Best model weights loaded before returning! best val_acc:86.03
Current FLOPS: 83278394880, Current params : 33497078
Validation accuracy  86.03